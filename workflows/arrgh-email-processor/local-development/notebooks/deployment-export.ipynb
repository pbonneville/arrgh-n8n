{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment Export and Configuration Generation\n",
    "\n",
    "This notebook handles the final step of the development workflow: exporting local LangGraph implementations to n8n-compatible configurations.\n",
    "\n",
    "## Objectives\n",
    "1. Export AI Agent node configurations\n",
    "2. Generate Memory node configurations\n",
    "3. Create workflow connection specifications\n",
    "4. Generate deployment scripts\n",
    "5. Validate configurations before deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from typing import Dict, List, Any, Optional\n",
    "from datetime import datetime\n",
    "import uuid\n",
    "\n",
    "# Load environment\n",
    "load_dotenv()\n",
    "\n",
    "# Add python modules to path\n",
    "project_root = Path().resolve().parent\n",
    "sys.path.append(str(project_root / 'python'))\n",
    "\n",
    "print(f\"Deployment export environment ready\")\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Current time: {datetime.now().isoformat()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n8n node configuration templates\n",
    "class N8nConfigTemplates:\n",
    "    \"\"\"Templates for generating n8n node configurations\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def ai_agent_node(system_message: str, position: List[int] = [1800, 260]) -> Dict[str, Any]:\n",
    "        \"\"\"Generate AI Agent node configuration\"\"\"\n",
    "        return {\n",
    "            \"parameters\": {\n",
    "                \"agent\": \"conversationalAgent\",\n",
    "                \"model\": {\n",
    "                    \"__rl\": True,\n",
    "                    \"mode\": \"list\",\n",
    "                    \"value\": \"claude-sonnet-4-20250514\",\n",
    "                    \"cachedResultName\": \"Claude 4 Sonnet\"\n",
    "                },\n",
    "                \"systemMessage\": system_message,\n",
    "                \"options\": {\n",
    "                    \"maxIterations\": 5,\n",
    "                    \"returnIntermediateSteps\": True,\n",
    "                    \"temperature\": 0.1\n",
    "                }\n",
    "            },\n",
    "            \"type\": \"@n8n/n8n-nodes-langchain.agent\",\n",
    "            \"typeVersion\": 1.8,\n",
    "            \"position\": position,\n",
    "            \"id\": str(uuid.uuid4()),\n",
    "            \"name\": \"AI Email Processor\",\n",
    "            \"credentials\": {\n",
    "                \"anthropicApi\": {\n",
    "                    \"id\": \"JfNCHfdN0o9xewV4\",  # Use existing credential ID\n",
    "                    \"name\": \"Anthropic account\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    @staticmethod\n",
    "    def memory_node(window_size: int = 5, position: List[int] = [1600, 400]) -> Dict[str, Any]:\n",
    "        \"\"\"Generate Memory Buffer Window node configuration\"\"\"\n",
    "        return {\n",
    "            \"parameters\": {\n",
    "                \"windowSize\": window_size,\n",
    "                \"returnMessages\": True,\n",
    "                \"inputKey\": \"input\",\n",
    "                \"outputKey\": \"history\"\n",
    "            },\n",
    "            \"type\": \"@n8n/n8n-nodes-langchain.memoryBufferWindow\",\n",
    "            \"typeVersion\": 1.3,\n",
    "            \"position\": position,\n",
    "            \"id\": str(uuid.uuid4()),\n",
    "            \"name\": \"Email Memory\"\n",
    "        }\n",
    "    \n",
    "    @staticmethod\n",
    "    def python_preprocessor_node(python_code: str, position: List[int] = [1580, 260]) -> Dict[str, Any]:\n",
    "        \"\"\"Generate Python preprocessing node configuration\"\"\"\n",
    "        return {\n",
    "            \"parameters\": {\n",
    "                \"language\": \"python\",\n",
    "                \"pythonCode\": python_code\n",
    "            },\n",
    "            \"type\": \"n8n-nodes-base.code\",\n",
    "            \"typeVersion\": 2,\n",
    "            \"position\": position,\n",
    "            \"id\": str(uuid.uuid4()),\n",
    "            \"name\": \"Prepare Email Data\"\n",
    "        }\n",
    "    \n",
    "    @staticmethod\n",
    "    def python_postprocessor_node(python_code: str, position: List[int] = [2020, 260]) -> Dict[str, Any]:\n",
    "        \"\"\"Generate Python postprocessing node configuration\"\"\"\n",
    "        return {\n",
    "            \"parameters\": {\n",
    "                \"language\": \"python\",\n",
    "                \"pythonCode\": python_code\n",
    "            },\n",
    "            \"type\": \"n8n-nodes-base.code\",\n",
    "            \"typeVersion\": 2,\n",
    "            \"position\": position,\n",
    "            \"id\": str(uuid.uuid4()),\n",
    "            \"name\": \"Process Results\"\n",
    "        }\n",
    "\n",
    "print(\"Configuration templates loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System Message Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate optimized system message for n8n AI Agent\n",
    "def generate_system_message() -> str:\n",
    "    \"\"\"Generate the system message for the AI Agent node\"\"\"\n",
    "    \n",
    "    system_message = \"\"\"\n",
    "You are an intelligent email processor for Arrgh systems. Your role is to analyze incoming emails and provide structured analysis.\n",
    "\n",
    "## Your Capabilities:\n",
    "1. **Email Categorization**: Classify emails into: invoice, support, sales, general, spam\n",
    "2. **Priority Assessment**: Determine urgency: high, medium, low\n",
    "3. **Entity Extraction**: Extract structured data (amounts, dates, names, contacts)\n",
    "4. **Action Recommendations**: Suggest appropriate next steps\n",
    "5. **Reasoning**: Provide clear explanations for your analysis\n",
    "\n",
    "## Analysis Guidelines:\n",
    "\n",
    "**Invoice Emails**: Look for payment requests, billing information, amounts, due dates\n",
    "- Keywords: invoice, bill, payment, due, amount, remittance\n",
    "- Priority: Usually medium, high if overdue or urgent\n",
    "\n",
    "**Support Emails**: Identify help requests, technical issues, questions\n",
    "- Keywords: help, support, issue, problem, error, bug, question\n",
    "- Priority: High if urgent/critical, medium for general support\n",
    "\n",
    "**Sales Emails**: Detect business opportunities, proposals, meetings\n",
    "- Keywords: proposal, quote, offer, deal, opportunity, meeting, demo\n",
    "- Priority: Medium for opportunities, low for general inquiries\n",
    "\n",
    "**Priority Indicators**:\n",
    "- High: urgent, asap, critical, emergency, important, deadline\n",
    "- Medium: follow-up, reminder, soon, this week\n",
    "- Low: when convenient, no rush, general information\n",
    "\n",
    "## Response Format:\n",
    "Always respond with a JSON object containing:\n",
    "```json\n",
    "{\n",
    "  \"category\": \"invoice|support|sales|general|spam\",\n",
    "  \"priority\": \"high|medium|low\",\n",
    "  \"confidence\": 0.95,\n",
    "  \"entities\": {\n",
    "    \"amounts\": [\"$1,250.00\"],\n",
    "    \"dates\": [\"July 23, 2025\"],\n",
    "    \"contacts\": [\"john@example.com\"],\n",
    "    \"invoice_numbers\": [\"INV-2025-001\"],\n",
    "    \"keywords\": [\"payment\", \"due\", \"invoice\"]\n",
    "  },\n",
    "  \"suggested_actions\": [\n",
    "    \"Forward to accounting team\",\n",
    "    \"Add to payment tracking system\",\n",
    "    \"Set calendar reminder for due date\"\n",
    "  ],\n",
    "  \"reasoning\": \"Email contains clear invoice information with specific amount and due date. Classified as medium priority invoice requiring payment processing.\"\n",
    "}\n",
    "```\n",
    "\n",
    "## Important Notes:\n",
    "- Be consistent with categorization\n",
    "- Provide confidence scores between 0.0 and 1.0\n",
    "- Extract all relevant entities accurately\n",
    "- Suggest actionable next steps\n",
    "- Keep reasoning concise but informative\n",
    "- Handle incomplete or unclear emails gracefully\n",
    "\"\"\".strip()\n",
    "    \n",
    "    return system_message\n",
    "\n",
    "# Generate and display system message\n",
    "system_message = generate_system_message()\n",
    "print(\"=== GENERATED SYSTEM MESSAGE ===\")\n",
    "print(system_message)\n",
    "print(f\"\\nLength: {len(system_message)} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Code Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Python code for preprocessing and postprocessing nodes\n",
    "def generate_preprocessing_code() -> str:\n",
    "    \"\"\"Generate Python code for email data preparation\"\"\"\n",
    "    \n",
    "    code = \"\"\"\n",
    "# Prepare email data for AI Agent processing\n",
    "# Input: Parsed email content from previous node\n",
    "# Output: Formatted data for AI Agent\n",
    "\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Get email data from previous node\n",
    "email_data = $input.first().json\n",
    "\n",
    "# Extract and clean email content\n",
    "email_from = email_data.get('from', '')\n",
    "email_subject = email_data.get('subject', '')\n",
    "email_body = email_data.get('body', '')\n",
    "email_timestamp = email_data.get('timestamp', '')\n",
    "message_id = email_data.get('messageId', '')\n",
    "\n",
    "# Generate thread ID for conversation tracking\n",
    "import hashlib\n",
    "thread_key = f\"{email_from}-{email_subject.replace('Re:', '').replace('Fwd:', '').strip()}\"\n",
    "thread_id = hashlib.md5(thread_key.encode()).hexdigest()[:8]\n",
    "\n",
    "# Prepare structured input for AI Agent\n",
    "ai_input = {\n",
    "    \"email_data\": {\n",
    "        \"id\": message_id,\n",
    "        \"from\": email_from,\n",
    "        \"subject\": email_subject,\n",
    "        \"body\": email_body,\n",
    "        \"timestamp\": email_timestamp,\n",
    "        \"thread_id\": thread_id\n",
    "    },\n",
    "    \"analysis_request\": {\n",
    "        \"categorize\": True,\n",
    "        \"extract_entities\": True,\n",
    "        \"assess_priority\": True,\n",
    "        \"suggest_actions\": True\n",
    "    },\n",
    "    \"context\": {\n",
    "        \"system\": \"email-processor\",\n",
    "        \"version\": \"2.0\",\n",
    "        \"processing_time\": datetime.now().isoformat()\n",
    "    }\n",
    "}\n",
    "\n",
    "# Log preprocessing info\n",
    "print(f\"Preprocessing email from {email_from}\")\n",
    "print(f\"Subject: {email_subject}\")\n",
    "print(f\"Thread ID: {thread_id}\")\n",
    "\n",
    "return ai_input\n",
    "\"\"\".strip()\n",
    "    \n",
    "    return code\n",
    "\n",
    "def generate_postprocessing_code() -> str:\n",
    "    \"\"\"Generate Python code for processing AI Agent results\"\"\"\n",
    "    \n",
    "    code = \"\"\"\n",
    "# Process AI Agent results and format final output\n",
    "# Input: AI Agent analysis results\n",
    "# Output: Formatted results for webhook response\n",
    "\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Get AI Agent output\n",
    "ai_result = $input.first().json\n",
    "\n",
    "# Get original email data from preprocessing node\n",
    "email_data = $('Prepare Email Data').first().json.get('email_data', {})\n",
    "\n",
    "# Parse AI response if it's a string\n",
    "if isinstance(ai_result, str):\n",
    "    try:\n",
    "        ai_analysis = json.loads(ai_result)\n",
    "    except json.JSONDecodeError:\n",
    "        # Fallback if AI response is not valid JSON\n",
    "        ai_analysis = {\n",
    "            \"category\": \"general\",\n",
    "            \"priority\": \"low\",\n",
    "            \"confidence\": 0.5,\n",
    "            \"entities\": {},\n",
    "            \"suggested_actions\": [\"Manual review required\"],\n",
    "            \"reasoning\": \"Failed to parse AI response\",\n",
    "            \"error\": \"Invalid JSON response from AI\"\n",
    "        }\n",
    "else:\n",
    "    ai_analysis = ai_result\n",
    "\n",
    "# Validate required fields\n",
    "required_fields = ['category', 'priority', 'confidence']\n",
    "for field in required_fields:\n",
    "    if field not in ai_analysis:\n",
    "        ai_analysis[field] = 'unknown' if field != 'confidence' else 0.0\n",
    "\n",
    "# Generate processing summary\n",
    "processing_summary = {\n",
    "    \"email_id\": email_data.get('id', 'unknown'),\n",
    "    \"processed_at\": datetime.now().isoformat(),\n",
    "    \"processing_result\": {\n",
    "        \"category\": ai_analysis.get('category', 'unknown'),\n",
    "        \"priority\": ai_analysis.get('priority', 'low'),\n",
    "        \"confidence\": ai_analysis.get('confidence', 0.0),\n",
    "        \"entities\": ai_analysis.get('entities', {}),\n",
    "        \"suggested_actions\": ai_analysis.get('suggested_actions', []),\n",
    "        \"reasoning\": ai_analysis.get('reasoning', 'No reasoning provided')\n",
    "    },\n",
    "    \"email_metadata\": {\n",
    "        \"from\": email_data.get('from', ''),\n",
    "        \"subject\": email_data.get('subject', ''),\n",
    "        \"timestamp\": email_data.get('timestamp', ''),\n",
    "        \"thread_id\": email_data.get('thread_id', '')\n",
    "    },\n",
    "    \"processing_status\": \"completed\",\n",
    "    \"system_info\": {\n",
    "        \"processor\": \"email-processor-v2\",\n",
    "        \"model\": \"claude-sonnet-4\",\n",
    "        \"workflow_version\": \"2.0.0\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Add error information if present\n",
    "if 'error' in ai_analysis:\n",
    "    processing_summary['error'] = ai_analysis['error']\n",
    "    processing_summary['processing_status'] = 'completed_with_errors'\n",
    "\n",
    "# Log processing result\n",
    "print(f\"Email {processing_summary['email_id']} processed successfully\")\n",
    "print(f\"Category: {processing_summary['processing_result']['category']}\")\n",
    "print(f\"Priority: {processing_summary['processing_result']['priority']}\")\n",
    "print(f\"Confidence: {processing_summary['processing_result']['confidence']}\")\n",
    "\n",
    "return processing_summary\n",
    "\"\"\".strip()\n",
    "    \n",
    "    return code\n",
    "\n",
    "# Generate code\n",
    "preprocessing_code = generate_preprocessing_code()\n",
    "postprocessing_code = generate_postprocessing_code()\n",
    "\n",
    "print(\"=== GENERATED PREPROCESSING CODE ===\")\n",
    "print(preprocessing_code[:300] + \"...\")\n",
    "print(f\"\\nPreprocessing code length: {len(preprocessing_code)} characters\")\n",
    "\n",
    "print(\"\\n=== GENERATED POSTPROCESSING CODE ===\")\n",
    "print(postprocessing_code[:300] + \"...\")\n",
    "print(f\"\\nPostprocessing code length: {len(postprocessing_code)} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Complete Node Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate all node configurations\n",
    "def generate_all_configurations() -> Dict[str, Any]:\n",
    "    \"\"\"Generate all required node configurations\"\"\"\n",
    "    \n",
    "    # Generate individual nodes\n",
    "    preprocessor_node = N8nConfigTemplates.python_preprocessor_node(\n",
    "        python_code=preprocessing_code,\n",
    "        position=[1580, 260]\n",
    "    )\n",
    "    \n",
    "    ai_agent_node = N8nConfigTemplates.ai_agent_node(\n",
    "        system_message=system_message,\n",
    "        position=[1800, 260]\n",
    "    )\n",
    "    \n",
    "    memory_node = N8nConfigTemplates.memory_node(\n",
    "        window_size=5,\n",
    "        position=[1600, 400]\n",
    "    )\n",
    "    \n",
    "    postprocessor_node = N8nConfigTemplates.python_postprocessor_node(\n",
    "        python_code=postprocessing_code,\n",
    "        position=[2020, 260]\n",
    "    )\n",
    "    \n",
    "    # Store node IDs for connection mapping\n",
    "    node_ids = {\n",
    "        \"preprocessor\": preprocessor_node[\"id\"],\n",
    "        \"ai_agent\": ai_agent_node[\"id\"],\n",
    "        \"memory\": memory_node[\"id\"],\n",
    "        \"postprocessor\": postprocessor_node[\"id\"]\n",
    "    }\n",
    "    \n",
    "    return {\n",
    "        \"nodes\": {\n",
    "            \"preprocessor\": preprocessor_node,\n",
    "            \"ai_agent\": ai_agent_node,\n",
    "            \"memory\": memory_node,\n",
    "            \"postprocessor\": postprocessor_node\n",
    "        },\n",
    "        \"node_ids\": node_ids,\n",
    "        \"metadata\": {\n",
    "            \"generated_at\": datetime.now().isoformat(),\n",
    "            \"version\": \"2.0.0\",\n",
    "            \"description\": \"Enhanced Arrgh Email Processor with AI Agent\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Generate configurations\n",
    "configurations = generate_all_configurations()\n",
    "\n",
    "print(\"=== GENERATED NODE CONFIGURATIONS ===\")\n",
    "for node_name, node_config in configurations[\"nodes\"].items():\n",
    "    print(f\"{node_name.title()}: {node_config['name']} ({node_config['type']})\")\n",
    "    print(f\"  ID: {node_config['id']}\")\n",
    "    print(f\"  Position: {node_config['position']}\")\n",
    "\n",
    "print(f\"\\nGenerated at: {configurations['metadata']['generated_at']}\")\n",
    "print(f\"Version: {configurations['metadata']['version']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Node Connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate node connection specifications\n",
    "def generate_node_connections(node_ids: Dict[str, str]) -> Dict[str, Any]:\n",
    "    \"\"\"Generate connection specifications for the new nodes\"\"\"\n",
    "    \n",
    "    connections = {\n",
    "        # Parse Email Content -> Prepare Email Data (preprocessor)\n",
    "        \"Parse Email Content\": {\n",
    "            \"main\": [\n",
    "                [\n",
    "                    {\n",
    "                        \"node\": \"Prepare Email Data\",\n",
    "                        \"type\": \"main\",\n",
    "                        \"index\": 0\n",
    "                    }\n",
    "                ]\n",
    "            ]\n",
    "        },\n",
    "        \n",
    "        # Prepare Email Data -> AI Email Processor (agent)\n",
    "        \"Prepare Email Data\": {\n",
    "            \"main\": [\n",
    "                [\n",
    "                    {\n",
    "                        \"node\": \"AI Email Processor\",\n",
    "                        \"type\": \"main\",\n",
    "                        \"index\": 0\n",
    "                    }\n",
    "                ]\n",
    "            ]\n",
    "        },\n",
    "        \n",
    "        # Email Memory -> AI Email Processor (memory connection)\n",
    "        \"Email Memory\": {\n",
    "            \"ai_memory\": [\n",
    "                [\n",
    "                    {\n",
    "                        \"node\": \"AI Email Processor\",\n",
    "                        \"type\": \"ai_memory\",\n",
    "                        \"index\": 0\n",
    "                    }\n",
    "                ]\n",
    "            ]\n",
    "        },\n",
    "        \n",
    "        # AI Email Processor -> Process Results (postprocessor)\n",
    "        \"AI Email Processor\": {\n",
    "            \"main\": [\n",
    "                [\n",
    "                    {\n",
    "                        \"node\": \"Process Results\",\n",
    "                        \"type\": \"main\",\n",
    "                        \"index\": 0\n",
    "                    }\n",
    "                ]\n",
    "            ]\n",
    "        },\n",
    "        \n",
    "        # Process Results -> Success Response\n",
    "        \"Process Results\": {\n",
    "            \"main\": [\n",
    "                [\n",
    "                    {\n",
    "                        \"node\": \"Success Response\",\n",
    "                        \"type\": \"main\",\n",
    "                        \"index\": 0\n",
    "                    }\n",
    "                ]\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return {\n",
    "        \"connections\": connections,\n",
    "        \"connection_summary\": {\n",
    "            \"total_connections\": len(connections),\n",
    "            \"flow_description\": \"Parse Email Content \u2192 Prepare Email Data \u2192 AI Email Processor (+ Email Memory) \u2192 Process Results \u2192 Success Response\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Generate connections\n",
    "connections_config = generate_node_connections(configurations[\"node_ids\"])\n",
    "\n",
    "print(\"=== GENERATED NODE CONNECTIONS ===\")\n",
    "print(f\"Flow: {connections_config['connection_summary']['flow_description']}\")\n",
    "print(f\"Total connections: {connections_config['connection_summary']['total_connections']}\")\n",
    "\n",
    "print(\"\\n=== CONNECTION DETAILS ===\")\n",
    "for source_node, connections in connections_config[\"connections\"].items():\n",
    "    for connection_type, targets in connections.items():\n",
    "        for target_list in targets:\n",
    "            for target in target_list:\n",
    "                print(f\"{source_node} --{connection_type}--> {target['node']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Complete Workflow Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create complete workflow export\n",
    "def create_workflow_export() -> Dict[str, Any]:\n",
    "    \"\"\"Create complete workflow configuration for n8n import\"\"\"\n",
    "    \n",
    "    # Combine all configurations\n",
    "    workflow_export = {\n",
    "        \"name\": \"Arrgh Email Processor - Enhanced\",\n",
    "        \"nodes\": list(configurations[\"nodes\"].values()),\n",
    "        \"connections\": connections_config[\"connections\"],\n",
    "        \"active\": False,  # Set to false for initial import\n",
    "        \"settings\": {\n",
    "            \"executionOrder\": \"v1\"\n",
    "        },\n",
    "        \"staticData\": None,\n",
    "        \"meta\": {\n",
    "            \"templateCredsSetupCompleted\": True,\n",
    "            \"generated_by\": \"n8n-development-workflow\",\n",
    "            \"version\": configurations[\"metadata\"][\"version\"],\n",
    "            \"generated_at\": configurations[\"metadata\"][\"generated_at\"]\n",
    "        },\n",
    "        \"pinData\": {},\n",
    "        \"tags\": [\"email-processing\", \"ai-enhanced\", \"production\"]\n",
    "    }\n",
    "    \n",
    "    return workflow_export\n",
    "\n",
    "# Create export\n",
    "workflow_export = create_workflow_export()\n",
    "\n",
    "print(\"=== WORKFLOW EXPORT SUMMARY ===\")\n",
    "print(f\"Workflow name: {workflow_export['name']}\")\n",
    "print(f\"Number of nodes: {len(workflow_export['nodes'])}\")\n",
    "print(f\"Number of connections: {len(workflow_export['connections'])}\")\n",
    "print(f\"Version: {workflow_export['meta']['version']}\")\n",
    "print(f\"Tags: {', '.join(workflow_export['tags'])}\")\n",
    "\n",
    "# Validate export structure\n",
    "required_fields = ['name', 'nodes', 'connections', 'active', 'settings']\n",
    "missing_fields = [field for field in required_fields if field not in workflow_export]\n",
    "\n",
    "if missing_fields:\n",
    "    print(f\"\\n\u274c Missing required fields: {missing_fields}\")\n",
    "else:\n",
    "    print(\"\\n\u2705 Workflow export structure is valid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Export Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all export files to deploy directory\n",
    "def save_export_files():\n",
    "    \"\"\"Save all generated configurations to files\"\"\"\n",
    "    \n",
    "    deploy_dir = project_root / 'deploy'\n",
    "    deploy_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Save individual node configurations\n",
    "    for node_name, node_config in configurations[\"nodes\"].items():\n",
    "        filename = f\"{node_name}-node-config.json\"\n",
    "        with open(deploy_dir / filename, 'w') as f:\n",
    "            json.dump(node_config, f, indent=2)\n",
    "        print(f\"Saved: {filename}\")\n",
    "    \n",
    "    # Save complete workflow export\n",
    "    with open(deploy_dir / 'email-processor-enhanced.json', 'w') as f:\n",
    "        json.dump(workflow_export, f, indent=2)\n",
    "    print(\"Saved: email-processor-enhanced.json\")\n",
    "    \n",
    "    # Save connections configuration\n",
    "    with open(deploy_dir / 'node-connections.json', 'w') as f:\n",
    "        json.dump(connections_config, f, indent=2)\n",
    "    print(\"Saved: node-connections.json\")\n",
    "    \n",
    "    # Save system message separately for easy editing\n",
    "    with open(deploy_dir / 'system-message.txt', 'w') as f:\n",
    "        f.write(system_message)\n",
    "    print(\"Saved: system-message.txt\")\n",
    "    \n",
    "    # Save Python code files\n",
    "    with open(deploy_dir / 'preprocessing-code.py', 'w') as f:\n",
    "        f.write(preprocessing_code)\n",
    "    print(\"Saved: preprocessing-code.py\")\n",
    "    \n",
    "    with open(deploy_dir / 'postprocessing-code.py', 'w') as f:\n",
    "        f.write(postprocessing_code)\n",
    "    print(\"Saved: postprocessing-code.py\")\n",
    "    \n",
    "    # Create deployment summary\n",
    "    deployment_summary = {\n",
    "        \"export_info\": {\n",
    "            \"generated_at\": datetime.now().isoformat(),\n",
    "            \"version\": configurations[\"metadata\"][\"version\"],\n",
    "            \"workflow_name\": workflow_export[\"name\"]\n",
    "        },\n",
    "        \"files_generated\": [\n",
    "            \"email-processor-enhanced.json\",\n",
    "            \"node-connections.json\",\n",
    "            \"system-message.txt\",\n",
    "            \"preprocessing-code.py\",\n",
    "            \"postprocessing-code.py\"\n",
    "        ] + [f\"{name}-node-config.json\" for name in configurations[\"nodes\"].keys()],\n",
    "        \"deployment_steps\": [\n",
    "            \"1. Import email-processor-enhanced.json into n8n\",\n",
    "            \"2. Verify node connections are correct\",\n",
    "            \"3. Test with webhook-test endpoint\",\n",
    "            \"4. Validate with real email data\",\n",
    "            \"5. Activate workflow for production\"\n",
    "        ],\n",
    "        \"node_summary\": {\n",
    "            \"total_nodes\": len(configurations[\"nodes\"]),\n",
    "            \"node_types\": {\n",
    "                \"python_code\": 2,\n",
    "                \"ai_agent\": 1,\n",
    "                \"memory\": 1\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    with open(deploy_dir / 'deployment-summary.json', 'w') as f:\n",
    "        json.dump(deployment_summary, f, indent=2)\n",
    "    print(\"Saved: deployment-summary.json\")\n",
    "    \n",
    "    return deploy_dir, deployment_summary\n",
    "\n",
    "# Save all files\n",
    "print(\"=== SAVING EXPORT FILES ===\")\n",
    "deploy_directory, summary = save_export_files()\n",
    "\n",
    "print(f\"\\n=== EXPORT COMPLETE ===\")\n",
    "print(f\"Deploy directory: {deploy_directory}\")\n",
    "print(f\"Files generated: {len(summary['files_generated'])}\")\n",
    "print(f\"Ready for deployment: {summary['export_info']['workflow_name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Deployment Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate deployment script for n8n API\n",
    "def generate_deployment_script() -> str:\n",
    "    \"\"\"Generate bash script for automated deployment\"\"\"\n",
    "    \n",
    "    script = f\"\"\"\n",
    "#!/bin/bash\n",
    "\n",
    "# Arrgh Email Processor Enhanced - Deployment Script\n",
    "# Generated: {datetime.now().isoformat()}\n",
    "# Version: {configurations['metadata']['version']}\n",
    "\n",
    "set -e  # Exit on any error\n",
    "\n",
    "# Configuration\n",
    "N8N_BASE_URL=\"${{N8N_BASE_URL:-https://n8n.paulbonneville.com}}\"\n",
    "N8N_API_KEY=\"${{N8N_API_KEY}}\"\n",
    "WORKFLOW_FILE=\"email-processor-enhanced.json\"\n",
    "\n",
    "# Colors for output\n",
    "RED='\\033[0;31m'\n",
    "GREEN='\\033[0;32m'\n",
    "YELLOW='\\033[1;33m'\n",
    "NC='\\033[0m' # No Color\n",
    "\n",
    "echo -e \"${{GREEN}}=== Arrgh Email Processor Enhanced Deployment ===${{NC}}\"\n",
    "echo \"Deploying to: $N8N_BASE_URL\"\n",
    "echo \"Workflow file: $WORKFLOW_FILE\"\n",
    "echo\n",
    "\n",
    "# Check if API key is set\n",
    "if [ -z \"$N8N_API_KEY\" ]; then\n",
    "    echo -e \"${{RED}}Error: N8N_API_KEY environment variable not set${{NC}}\"\n",
    "    echo \"Please set your n8n API key:\"\n",
    "    echo \"export N8N_API_KEY=your_api_key_here\"\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "# Check if workflow file exists\n",
    "if [ ! -f \"$WORKFLOW_FILE\" ]; then\n",
    "    echo -e \"${{RED}}Error: Workflow file $WORKFLOW_FILE not found${{NC}}\"\n",
    "    echo \"Please run the deployment export notebook first\"\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "# Function to make API calls\n",
    "api_call() {{\n",
    "    local method=$1\n",
    "    local endpoint=$2\n",
    "    local data=$3\n",
    "    \n",
    "    curl -s -X \"$method\" \\\n",
    "        \"$N8N_BASE_URL/api/v1/$endpoint\" \\\n",
    "        -H \"Authorization: Bearer $N8N_API_KEY\" \\\n",
    "        -H \"Content-Type: application/json\" \\\n",
    "        -d \"$data\"\n",
    "}}\n",
    "\n",
    "# Step 1: Check if workflow already exists\n",
    "echo -e \"${{YELLOW}}Step 1: Checking existing workflows...${{NC}}\"\n",
    "existing_workflows=$(api_call \"GET\" \"workflows\" \"\")\n",
    "\n",
    "workflow_id=$(echo \"$existing_workflows\" | jq -r '.data[] | select(.name == \"Arrgh Email Processor - Enhanced\") | .id')\n",
    "\n",
    "if [ \"$workflow_id\" != \"null\" ] && [ -n \"$workflow_id\" ]; then\n",
    "    echo \"Found existing workflow with ID: $workflow_id\"\n",
    "    echo -e \"${{YELLOW}}Updating existing workflow...${{NC}}\"\n",
    "    \n",
    "    # Update existing workflow\n",
    "    result=$(api_call \"PUT\" \"workflows/$workflow_id\" \"$(cat $WORKFLOW_FILE)\")\n",
    "    \n",
    "    if echo \"$result\" | jq -e '.id' > /dev/null; then\n",
    "        echo -e \"${{GREEN}}\u2713 Workflow updated successfully${{NC}}\"\n",
    "    else\n",
    "        echo -e \"${{RED}}\u2717 Failed to update workflow${{NC}}\"\n",
    "        echo \"Error: $result\"\n",
    "        exit 1\n",
    "    fi\n",
    "else\n",
    "    echo \"No existing workflow found\"\n",
    "    echo -e \"${{YELLOW}}Creating new workflow...${{NC}}\"\n",
    "    \n",
    "    # Create new workflow\n",
    "    result=$(api_call \"POST\" \"workflows\" \"$(cat $WORKFLOW_FILE)\")\n",
    "    \n",
    "    if echo \"$result\" | jq -e '.id' > /dev/null; then\n",
    "        workflow_id=$(echo \"$result\" | jq -r '.id')\n",
    "        echo -e \"${{GREEN}}\u2713 Workflow created successfully with ID: $workflow_id${{NC}}\"\n",
    "    else\n",
    "        echo -e \"${{RED}}\u2717 Failed to create workflow${{NC}}\"\n",
    "        echo \"Error: $result\"\n",
    "        exit 1\n",
    "    fi\n",
    "fi\n",
    "\n",
    "# Step 2: Test workflow (optional)\n",
    "echo -e \"${{YELLOW}}Step 2: Testing workflow...${{NC}}\"\n",
    "echo \"You can test the workflow using:\"\n",
    "echo \"./test-sns-webhook.sh test\"\n",
    "\n",
    "# Step 3: Activation prompt\n",
    "echo -e \"${{YELLOW}}Step 3: Workflow activation${{NC}}\"\n",
    "echo \"Workflow deployed but not activated\"\n",
    "echo \"To activate, run:\"\n",
    "echo \"curl -X POST '$N8N_BASE_URL/api/v1/workflows/$workflow_id/activate' -H 'Authorization: Bearer $N8N_API_KEY'\"\n",
    "\n",
    "echo\n",
    "echo -e \"${{GREEN}}=== Deployment Complete ===${{NC}}\"\n",
    "echo \"Workflow ID: $workflow_id\"\n",
    "echo \"Status: Deployed (inactive)\"\n",
    "echo \"Next steps:\"\n",
    "echo \"1. Test the workflow with test data\"\n",
    "echo \"2. Verify all nodes are working correctly\"\n",
    "echo \"3. Activate the workflow for production use\"\n",
    "\"\"\".strip()\n",
    "    \n",
    "    return script\n",
    "\n",
    "# Generate and save deployment script\n",
    "deployment_script = generate_deployment_script()\n",
    "\n",
    "with open(deploy_directory / 'deploy.sh', 'w') as f:\n",
    "    f.write(deployment_script)\n",
    "\n",
    "# Make script executable\n",
    "import stat\n",
    "script_path = deploy_directory / 'deploy.sh'\n",
    "script_path.chmod(script_path.stat().st_mode | stat.S_IEXEC)\n",
    "\n",
    "print(\"=== DEPLOYMENT SCRIPT GENERATED ===\")\n",
    "print(f\"Script saved: {script_path}\")\n",
    "print(\"\\nTo deploy, run:\")\n",
    "print(f\"cd {deploy_directory}\")\n",
    "print(\"export N8N_API_KEY=your_api_key_here\")\n",
    "print(\"./deploy.sh\")\n",
    "\n",
    "print(\"\\nScript preview:\")\n",
    "print(deployment_script[:500] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Validation and Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform final validation of all exports\n",
    "def final_validation() -> Dict[str, bool]:\n",
    "    \"\"\"Perform comprehensive validation of all generated files\"\"\"\n",
    "    \n",
    "    validation_results = {}\n",
    "    \n",
    "    # Check file existence\n",
    "    required_files = [\n",
    "        'email-processor-enhanced.json',\n",
    "        'deployment-summary.json',\n",
    "        'deploy.sh',\n",
    "        'system-message.txt',\n",
    "        'preprocessing-code.py',\n",
    "        'postprocessing-code.py'\n",
    "    ]\n",
    "    \n",
    "    for filename in required_files:\n",
    "        file_path = deploy_directory / filename\n",
    "        validation_results[f\"file_exists_{filename}\"] = file_path.exists()\n",
    "    \n",
    "    # Validate JSON files\n",
    "    json_files = ['email-processor-enhanced.json', 'deployment-summary.json']\n",
    "    for filename in json_files:\n",
    "        try:\n",
    "            with open(deploy_directory / filename, 'r') as f:\n",
    "                json.load(f)\n",
    "            validation_results[f\"valid_json_{filename}\"] = True\n",
    "        except (json.JSONDecodeError, FileNotFoundError):\n",
    "            validation_results[f\"valid_json_{filename}\"] = False\n",
    "    \n",
    "    # Validate workflow structure\n",
    "    try:\n",
    "        required_workflow_fields = ['name', 'nodes', 'connections', 'active', 'settings']\n",
    "        missing_fields = [field for field in required_workflow_fields if field not in workflow_export]\n",
    "        validation_results['workflow_structure_valid'] = len(missing_fields) == 0\n",
    "    except:\n",
    "        validation_results['workflow_structure_valid'] = False\n",
    "    \n",
    "    # Validate node configurations\n",
    "    node_validation = True\n",
    "    for node_name, node_config in configurations[\"nodes\"].items():\n",
    "        required_node_fields = ['id', 'name', 'type', 'parameters', 'position']\n",
    "        if not all(field in node_config for field in required_node_fields):\n",
    "            node_validation = False\n",
    "            break\n",
    "    \n",
    "    validation_results['all_nodes_valid'] = node_validation\n",
    "    \n",
    "    # Validate system message length\n",
    "    validation_results['system_message_appropriate_length'] = 100 < len(system_message) < 5000\n",
    "    \n",
    "    # Validate Python code\n",
    "    validation_results['preprocessing_code_not_empty'] = len(preprocessing_code.strip()) > 0\n",
    "    validation_results['postprocessing_code_not_empty'] = len(postprocessing_code.strip()) > 0\n",
    "    \n",
    "    return validation_results\n",
    "\n",
    "# Run final validation\n",
    "validation_results = final_validation()\n",
    "\n",
    "print(\"=== FINAL VALIDATION RESULTS ===\")\n",
    "all_passed = True\n",
    "for check, passed in validation_results.items():\n",
    "    status = \"\u2705 PASS\" if passed else \"\u274c FAIL\"\n",
    "    print(f\"{status} - {check.replace('_', ' ').title()}\")\n",
    "    if not passed:\n",
    "        all_passed = False\n",
    "\n",
    "print(f\"\\n=== OVERALL VALIDATION: {'\u2705 ALL CHECKS PASSED' if all_passed else '\u274c SOME CHECKS FAILED'} ===\")\n",
    "\n",
    "if all_passed:\n",
    "    print(\"\\n\ud83d\ude80 READY FOR DEPLOYMENT!\")\n",
    "    print(\"\\nNext steps:\")\n",
    "    print(\"1. Review generated files in deploy/ directory\")\n",
    "    print(\"2. Set N8N_API_KEY environment variable\")\n",
    "    print(\"3. Run ./deploy.sh to deploy to n8n\")\n",
    "    print(\"4. Test with webhook-test endpoint\")\n",
    "    print(\"5. Activate workflow for production\")\nelse:\n",
    "    print(\"\\n\u26a0\ufe0f  Please fix validation errors before deployment\")\n",
    "\n",
    "print(f\"\\n=== EXPORT SUMMARY ===\")\n",
    "print(f\"Workflow: {workflow_export['name']}\")\n",
    "print(f\"Version: {configurations['metadata']['version']}\")\n",
    "print(f\"Nodes: {len(workflow_export['nodes'])}\")\n",
    "print(f\"Files generated: {len(summary['files_generated'])}\")\n",
    "print(f\"Deploy directory: {deploy_directory}\")\n",
    "print(f\"Generated at: {configurations['metadata']['generated_at']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}