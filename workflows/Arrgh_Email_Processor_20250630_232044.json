{
  "createdAt": "2025-06-27T08:19:00.509Z",
  "updatedAt": "2025-07-01T05:13:51.734Z",
  "id": "OXZoJZO8QesvwtWy",
  "name": "Arrgh Email Processor",
  "active": true,
  "isArchived": false,
  "nodes": [
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "inbound-email",
        "responseMode": "responseNode",
        "options": {}
      },
      "id": "23984477-973e-4060-84ea-082617395dee",
      "name": "Webhook",
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 1,
      "position": [
        -440,
        100
      ],
      "webhookId": "inbound-email"
    },
    {
      "parameters": {
        "conditions": {
          "string": [
            {
              "value1": "={{ $json.headers['x-amz-sns-message-type'] }}",
              "value2": "SubscriptionConfirmation"
            }
          ]
        }
      },
      "id": "1b9419e0-37e0-4271-af5d-adf89facd230",
      "name": "Is Subscription Confirmation?",
      "type": "n8n-nodes-base.if",
      "typeVersion": 1,
      "position": [
        -220,
        100
      ]
    },
    {
      "parameters": {
        "url": "={{ $json.body.parseJson().SubscribeURL}}",
        "options": {}
      },
      "id": "04221f1d-8a6e-4a39-be5b-874132ed9b39",
      "name": "Confirm Subscription",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.1,
      "position": [
        0,
        0
      ]
    },
    {
      "parameters": {
        "conditions": {
          "string": [
            {
              "value1": "={{ $json.body.parseJson().Type}}",
              "value2": "Notification"
            }
          ]
        }
      },
      "id": "de77b66d-f6d7-4de9-bf3d-5a11323447a7",
      "name": "Is Email Notification?",
      "type": "n8n-nodes-base.if",
      "typeVersion": 1,
      "position": [
        0,
        200
      ]
    },
    {
      "parameters": {
        "jsCode": " // First, let's see what we're actually receiving\n  console.log('Input data:', JSON.stringify($json, null, 2));\n\n  // Parse the SNS message from the webhook\n  let snsMessage;\n  if ($json.body) {\n    // If body is a string, parse it\n    if (typeof $json.body === 'string') {\n      const snsBody = JSON.parse($json.body);\n      snsMessage = JSON.parse(snsBody.Message);\n    } else {\n      // If body is already an object\n      snsMessage = JSON.parse($json.body.Message);\n    }\n  } else if ($json.Message) {\n    // Direct Message field\n    snsMessage = JSON.parse($json.Message);\n  } else {\n    throw new Error('Could not find SNS Message in input data');\n  }\n\n  // Extract email details from SES notification\n  const emailData = {\n    messageId: snsMessage.mail.messageId,\n    timestamp: snsMessage.mail.timestamp,\n    source: snsMessage.mail.source,\n    destination: snsMessage.mail.destination,\n    commonHeaders: snsMessage.mail.commonHeaders,\n    receipt: snsMessage.receipt,\n    // Use the messageId to construct S3 key\n    s3Bucket: \"n8n-inbound-emails-production\",\n    s3ObjectKey: \"emails/\" + snsMessage.mail.messageId\n  };\n\n  return emailData;"
      },
      "id": "3f9720bb-0b84-4a90-a489-00bc74f00382",
      "name": "Parse Email Metadata",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        220,
        200
      ]
    },
    {
      "parameters": {
        "url": "=https://s3.us-west-2.amazonaws.com/{{ $json.s3Bucket }}/{{ $json.s3ObjectKey }}",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "aws",
        "options": {
          "response": {
            "response": {
              "responseFormat": "text"
            }
          }
        }
      },
      "id": "5de7666d-051a-46ba-999c-24dd76012bfd",
      "name": "Download Email from S3",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.1,
      "position": [
        440,
        200
      ],
      "credentials": {
        "aws": {
          "id": "WpxeZn2MOJCZog1P",
          "name": "AWS account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// Parse the raw email content\nconst emailContent = $json.data;\n\n// Simple email parsing (you might want to use a more robust parser)\nconst lines = emailContent.split('\\n');\nlet inHeaders = true;\nlet headers = {};\nlet body = '';\nlet currentHeader = '';\n\nfor (let line of lines) {\n  if (inHeaders) {\n    if (line.trim() === '') {\n      inHeaders = false;\n      continue;\n    }\n    \n    if (line.startsWith(' ') || line.startsWith('\\t')) {\n      // Continuation of previous header\n      if (currentHeader) {\n        headers[currentHeader] += ' ' + line.trim();\n      }\n    } else {\n      // New header\n      const colonIndex = line.indexOf(':');\n      if (colonIndex > 0) {\n        currentHeader = line.substring(0, colonIndex).toLowerCase();\n        headers[currentHeader] = line.substring(colonIndex + 1).trim();\n      }\n    }\n  } else {\n    body += line + '\\n';\n  }\n}\n\n// Extract common email fields\nconst parsedEmail = {\n  messageId: $input.first().json.messageId,\n  timestamp: $input.first().json.timestamp,\n  from: headers['from'] || '',\n  to: headers['to'] || '',\n  subject: headers['subject'] || '',\n  date: headers['date'] || '',\n  body: body.trim(),\n  headers: headers,\n  rawContent: emailContent\n};\n\nreturn parsedEmail;"
      },
      "id": "7525ba66-dd3b-484f-be6b-accaca0d8a58",
      "name": "Parse Email Content",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        660,
        200
      ]
    },
    {
      "parameters": {
        "respondWith": "text",
        "responseBody": "Email processed successfully",
        "options": {}
      },
      "id": "7d138cd6-b5c3-4462-941b-9e499735a948",
      "name": "Success Response",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1,
      "position": [
        1320,
        200
      ]
    },
    {
      "parameters": {
        "respondWith": "text",
        "responseBody": "Subscription confirmed",
        "options": {}
      },
      "id": "ddafa2d9-79aa-4d31-bfef-90dee2cdad25",
      "name": "Subscription Response",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1,
      "position": [
        220,
        0
      ]
    },
    {
      "parameters": {
        "fromEmail": "paul@paulbonneville.com",
        "toEmail": "test@arrgh.paulbonneville.com",
        "subject": "HTML Test Email - Entity Extraction Test",
        "html": "<html><body><h1>Business Meeting Invitation</h1><p>Dear Team,</p><p><strong>John Smith</strong> from <em>Acme Corporation</em> has invited us to attend the <strong>Annual Tech Summit 2025</strong> in <a href=\"https://example.com\">San Francisco, California</a> on March 15-17, 2025.</p><ul><li>Event: Annual Tech Summit 2025</li><li>Organizer: Acme Corporation</li><li>Location: Moscone Center, San Francisco</li><li>Attendees: John Smith (CEO), Sarah Johnson (CTO)</li></ul><h3>Products to be Showcased</h3><p>They will be demonstrating their new <code>CloudSync Pro</code> software and the <strong>DataVault 3000</strong> hardware solution.</p><h3>Meeting Details</h3><blockquote>Please confirm attendance for the product demonstration at the Google Inc headquarters in Mountain View.</blockquote><p>Best regards,<br><strong>Alice Cooper</strong><br>Microsoft Corporation<br>Event Coordinator</p></body></html>",
        "options": {
          "appendAttribution": true
        }
      },
      "type": "n8n-nodes-base.emailSend",
      "typeVersion": 2.1,
      "position": [
        -440,
        440
      ],
      "id": "db5287b1-fdc4-4b13-aa47-418a61010c9d",
      "name": "Send email",
      "webhookId": "1db1a785-4a68-4274-b39e-4220d8fc3067",
      "credentials": {
        "smtp": {
          "id": "vIWuEOmeiLpSP3mN",
          "name": "SMTP account"
        }
      }
    },
    {
      "parameters": {
        "language": "python",
        "pythonCode": "# HTML to Markdown Conversion\nimport subprocess\nimport sys\nimport os\nfrom datetime import datetime\n\n# Get the parsed email data from previous node\njson_data = _input.first().json.to_py()\n\n# Extract email body (which may contain HTML)\nemail_body = json_data.get('body', '')\nemail_from = json_data.get('from', '')\nemail_subject = json_data.get('subject', '')\n\n# Function to install package\ndef install_package(package):\n    try:\n        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--user\", package], \n                            stdout=subprocess.DEVNULL, \n                            stderr=subprocess.DEVNULL)\n        return True\n    except:\n        return False\n\n# Try different approaches for HTML to Markdown conversion\nmarkdown_body = email_body\nconversion_method = \"none\"\n\nif '<' in email_body and '>' in email_body:\n    # First try: markdownify\n    try:\n        from markdownify import markdownify as md\n        conversion_method = \"markdownify\"\n    except ImportError:\n        # Try to install markdownify\n        if install_package('markdownify'):\n            try:\n                from markdownify import markdownify as md\n                conversion_method = \"markdownify\"\n            except:\n                pass\n    \n    # If markdownify is available, use it\n    if conversion_method == \"markdownify\":\n        try:\n            markdown_body = md(\n                email_body,\n                heading_style=\"ATX\",\n                bullets=\"-\",\n                code_language=\"\",\n                escape_asterisks=False,\n                escape_underscores=False\n            ).strip()\n        except Exception as e:\n            print(f\"Markdownify error: {str(e)}\")\n            conversion_method = \"fallback\"\n    \n    # Fallback: Use html2text if markdownify fails\n    if conversion_method != \"markdownify\":\n        try:\n            import html2text\n            h = html2text.HTML2Text()\n            h.ignore_links = False\n            h.body_width = 0  # Don't wrap lines\n            markdown_body = h.handle(email_body).strip()\n            conversion_method = \"html2text\"\n        except ImportError:\n            # Try to install html2text\n            if install_package('html2text'):\n                try:\n                    import html2text\n                    h = html2text.HTML2Text()\n                    h.ignore_links = False\n                    h.body_width = 0\n                    markdown_body = h.handle(email_body).strip()\n                    conversion_method = \"html2text\"\n                except:\n                    pass\n    \n    # Last resort: Basic regex conversion\n    if conversion_method == \"none\" or conversion_method == \"fallback\":\n        import re\n        \n        # Basic HTML to Markdown conversion\n        markdown = email_body\n        \n        # Remove script and style tags\n        markdown = re.sub(r'<script[^>]*>.*?</script>', '', markdown, flags=re.DOTALL | re.IGNORECASE)\n        markdown = re.sub(r'<style[^>]*>.*?</style>', '', markdown, flags=re.DOTALL | re.IGNORECASE)\n        \n        # Convert common tags\n        markdown = re.sub(r'<h1[^>]*>(.*?)</h1>', r'# \\1', markdown, flags=re.DOTALL | re.IGNORECASE)\n        markdown = re.sub(r'<h2[^>]*>(.*?)</h2>', r'## \\1', markdown, flags=re.DOTALL | re.IGNORECASE)\n        markdown = re.sub(r'<h3[^>]*>(.*?)</h3>', r'### \\1', markdown, flags=re.DOTALL | re.IGNORECASE)\n        markdown = re.sub(r'<strong[^>]*>(.*?)</strong>', r'**\\1**', markdown, flags=re.DOTALL | re.IGNORECASE)\n        markdown = re.sub(r'<b[^>]*>(.*?)</b>', r'**\\1**', markdown, flags=re.DOTALL | re.IGNORECASE)\n        markdown = re.sub(r'<em[^>]*>(.*?)</em>', r'*\\1*', markdown, flags=re.DOTALL | re.IGNORECASE)\n        markdown = re.sub(r'<i[^>]*>(.*?)</i>', r'*\\1*', markdown, flags=re.DOTALL | re.IGNORECASE)\n        markdown = re.sub(r'<a[^>]*href=[\"\\']([^\"\\'>]*)[\"\\'][^>]*>(.*?)</a>', r'[\\2](\\1)', markdown, flags=re.DOTALL | re.IGNORECASE)\n        markdown = re.sub(r'<code[^>]*>(.*?)</code>', r'`\\1`', markdown, flags=re.DOTALL | re.IGNORECASE)\n        markdown = re.sub(r'<blockquote[^>]*>(.*?)</blockquote>', r'> \\1', markdown, flags=re.DOTALL | re.IGNORECASE)\n        markdown = re.sub(r'<li[^>]*>(.*?)</li>', r'- \\1', markdown, flags=re.DOTALL | re.IGNORECASE)\n        markdown = re.sub(r'<br[^>]*/?>', '\\n', markdown, flags=re.IGNORECASE)\n        markdown = re.sub(r'<p[^>]*>', '', markdown, flags=re.IGNORECASE)\n        markdown = re.sub(r'</p>', '\\n\\n', markdown, flags=re.IGNORECASE)\n        markdown = re.sub(r'<[^>]+>', '', markdown)  # Remove remaining tags\n        markdown = re.sub(r'\\n\\s*\\n\\s*\\n', '\\n\\n', markdown)  # Clean up whitespace\n        \n        markdown_body = markdown.strip()\n        conversion_method = \"regex\"\n\n# Log the conversion for debugging\nprint(f'Email from: {email_from}')\nprint(f'Subject: {email_subject}')\nprint(f'HTML detected: {\"<\" in email_body and \">\" in email_body}')\nprint(f'Conversion method: {conversion_method}')\nprint(f'Original body length: {len(email_body)}')\nprint(f'Markdown body length: {len(markdown_body)}')\nprint('--- MARKDOWN BODY ---')\nprint(markdown_body[:500] if markdown_body else \"(empty)\")  # First 500 chars\n\n# Return the email data with markdown conversion\nreturn {\n    'messageId': json_data.get('messageId', ''),\n    'timestamp': json_data.get('timestamp', ''),\n    'from': email_from,\n    'to': json_data.get('to', ''),\n    'subject': email_subject,\n    'originalBody': email_body,\n    'markdownBody': markdown_body,\n    'isHtml': '<' in email_body and '>' in email_body,\n    'processedAt': datetime.now().isoformat(),\n    'conversionMethod': conversion_method\n}"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        880,
        200
      ],
      "id": "8355bc68-936f-42af-89a8-37146d8f4af3",
      "name": "Process Content"
    },
    {
      "parameters": {
        "language": "python",
        "pythonCode": "# Entity Extraction using built-in Python libraries\nimport re\nimport json\nfrom datetime import datetime\n\ndef extract_entities_basic(text):\n    \"\"\"Basic entity extraction using regex patterns\"\"\"\n    \n    # Initialize entity lists\n    entities = {\n        'people': [],\n        'organizations': [],\n        'places': [],\n        'events': [],\n        'products': []\n    }\n    \n    # Common patterns for people (Title + Name)\n    people_patterns = [\n        r'\\b(Mr\\.|Mrs\\.|Ms\\.|Dr\\.|Prof\\.)\\s+([A-Z][a-z]+\\s+[A-Z][a-z]+)',\n        r'\\b([A-Z][a-z]+\\s+[A-Z][a-z]+)\\s+\\((CEO|CTO|CFO|President|Director|Manager)\\)',\n        r'\\*\\*([A-Z][a-z]+\\s+[A-Z][a-z]+)\\*\\*',  # Bold names\n        r'([A-Z][a-z]+\\s+[A-Z][a-z]+)\\s+(from|at)\\s+'\n    ]\n    \n    # Organization patterns\n    org_patterns = [\n        r'\\*([A-Z][a-zA-Z\\s&]+Corporation)\\*',\n        r'([A-Z][a-zA-Z\\s&]+\\s+(Inc|Corporation|Corp|LLC|Ltd|Company))',\n        r'\\b([A-Z][a-zA-Z\\s&]+\\s+(Inc|Corporation|Corp|LLC|Ltd))\\b'\n    ]\n    \n    # Place patterns\n    place_patterns = [\n        r'\\b([A-Z][a-zA-Z\\s]+,\\s+[A-Z][a-zA-Z\\s]+)\\b',  # City, State\n        r'\\b([A-Z][a-zA-Z\\s]+\\s+(Center|Building|Hall|Stadium|Arena))\\b',\n        r'\\b(San Francisco|New York|Los Angeles|Chicago|Boston|Seattle|Mountain View)\\b'\n    ]\n    \n    # Event patterns  \n    event_patterns = [\n        r'\\*\\*([A-Z][a-zA-Z\\s0-9]+\\s+(Summit|Conference|Meeting|Event))\\*\\*',\n        r'\\b([A-Z][a-zA-Z\\s0-9]+\\s+(Summit|Conference|Meeting|Event|Demonstration))\\b'\n    ]\n    \n    # Product patterns\n    product_patterns = [\n        r'`([A-Z][a-zA-Z\\s0-9]+)`',  # Code formatted products\n        r'\\*\\*([A-Z][a-zA-Z\\s0-9]+)\\*\\*(?=\\s+(software|hardware|solution|tool|platform))',\n        r'\\b([A-Z][a-zA-Z\\s0-9]+\\s+(Pro|Plus|Enterprise|Suite|Platform))\\b'\n    ]\n    \n    # Extract people\n    for pattern in people_patterns:\n        matches = re.findall(pattern, text, re.IGNORECASE)\n        for match in matches:\n            if isinstance(match, tuple):\n                name = ' '.join([m for m in match if m and not m.lower() in ['mr.', 'mrs.', 'ms.', 'dr.', 'prof.', 'from', 'at', 'ceo', 'cto', 'cfo', 'president', 'director', 'manager']])\n            else:\n                name = match\n            if name and len(name.split()) >= 2:\n                entities['people'].append({\n                    'name': name.strip(),\n                    'context': f'Mentioned in email content'\n                })\n    \n    # Extract organizations\n    for pattern in org_patterns:\n        matches = re.findall(pattern, text, re.IGNORECASE)\n        for match in matches:\n            org_name = match if isinstance(match, str) else match[0]\n            if org_name:\n                entities['organizations'].append({\n                    'name': org_name.strip(),\n                    'type': 'company',\n                    'context': 'Referenced in email'\n                })\n    \n    # Extract places\n    for pattern in place_patterns:\n        matches = re.findall(pattern, text, re.IGNORECASE)\n        for match in matches:\n            place_name = match if isinstance(match, str) else match[0]\n            if place_name:\n                entities['places'].append({\n                    'name': place_name.strip(),\n                    'type': 'location',\n                    'context': 'Location mentioned in email'\n                })\n    \n    # Extract events\n    for pattern in event_patterns:\n        matches = re.findall(pattern, text, re.IGNORECASE)\n        for match in matches:\n            event_name = match if isinstance(match, str) else match[0]\n            if event_name:\n                entities['events'].append({\n                    'name': event_name.strip(),\n                    'context': 'Event referenced in email'\n                })\n    \n    # Extract products\n    for pattern in product_patterns:\n        matches = re.findall(pattern, text, re.IGNORECASE)\n        for match in matches:\n            product_name = match if isinstance(match, str) else match[0]\n            if product_name:\n                entities['products'].append({\n                    'name': product_name.strip(),\n                    'category': 'software/hardware',\n                    'context': 'Product mentioned in email'\n                })\n    \n    # Remove duplicates while preserving order\n    for category in entities:\n        seen = set()\n        unique_entities = []\n        for entity in entities[category]:\n            entity_key = entity['name'].lower()\n            if entity_key not in seen:\n                seen.add(entity_key)\n                unique_entities.append(entity)\n        entities[category] = unique_entities\n    \n    return entities\n\n# Get the processed email data from previous node\njson_data = _input.first().json.to_py()\n\n# Extract the markdown content\nmarkdown_content = json_data.get('markdownBody', '')\nemail_from = json_data.get('from', '')\nemail_subject = json_data.get('subject', '')\n\nprint(f'Processing entity extraction for email from: {email_from}')\nprint(f'Subject: {email_subject}')\nprint(f'Content length: {len(markdown_content)} characters')\nprint('--- CONTENT SAMPLE ---')\nprint(markdown_content[:300])\n\n# Extract entities\nextracted_entities = extract_entities_basic(markdown_content)\n\n# Log extraction results\nprint('\\n--- ENTITY EXTRACTION RESULTS ---')\nfor category, entities in extracted_entities.items():\n    print(f'{category.upper()}: {len(entities)} found')\n    for entity in entities:\n        print(f'  - {entity[\"name\"]}')\n\n# Return combined data\nreturn {\n    # Original email data\n    'messageId': json_data.get('messageId', ''),\n    'timestamp': json_data.get('timestamp', ''),\n    'from': email_from,\n    'to': json_data.get('to', ''),\n    'subject': email_subject,\n    'originalBody': json_data.get('originalBody', ''),\n    'markdownBody': markdown_content,\n    'isHtml': json_data.get('isHtml', False),\n    'processedAt': json_data.get('processedAt', ''),\n    \n    # Extracted entities\n    'entities': extracted_entities,\n    'entityExtractionAt': datetime.now().isoformat(),\n    \n    # Summary\n    'entitySummary': {\n        'totalPeople': len(extracted_entities['people']),\n        'totalOrganizations': len(extracted_entities['organizations']),\n        'totalPlaces': len(extracted_entities['places']),\n        'totalEvents': len(extracted_entities['events']),\n        'totalProducts': len(extracted_entities['products'])\n    }\n}"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1100,
        200
      ],
      "id": "9f8e7d6c-5b4a-3c2d-1e0f-a9b8c7d6e5f4",
      "name": "Entity Extractor"
    }
  ],
  "connections": {
    "Webhook": {
      "main": [
        [
          {
            "node": "Is Subscription Confirmation?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Is Subscription Confirmation?": {
      "main": [
        [
          {
            "node": "Confirm Subscription",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Is Email Notification?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Confirm Subscription": {
      "main": [
        [
          {
            "node": "Subscription Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Is Email Notification?": {
      "main": [
        [
          {
            "node": "Parse Email Metadata",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Parse Email Metadata": {
      "main": [
        [
          {
            "node": "Download Email from S3",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Download Email from S3": {
      "main": [
        [
          {
            "node": "Parse Email Content",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Parse Email Content": {
      "main": [
        [
          {
            "node": "Process Content",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Process Content": {
      "main": [
        [
          {
            "node": "Entity Extractor",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Entity Extractor": {
      "main": [
        [
          {
            "node": "Success Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "settings": {
    "executionOrder": "v1"
  },
  "staticData": null,
  "meta": {
    "templateCredsSetupCompleted": true
  },
  "pinData": {},
  "versionId": "5ff5dc95-7b2f-4cc2-b6ce-6230c166ae76",
  "triggerCount": 1,
  "shared": [
    {
      "createdAt": "2025-06-27T08:19:00.509Z",
      "updatedAt": "2025-06-27T08:19:00.509Z",
      "role": "workflow:owner",
      "workflowId": "OXZoJZO8QesvwtWy",
      "projectId": "KRe5oDYWZLNq5WHX",
      "project": {
        "createdAt": "2025-06-27T08:10:34.980Z",
        "updatedAt": "2025-06-27T08:11:37.105Z",
        "id": "KRe5oDYWZLNq5WHX",
        "name": "Paul Bonneville <paul@paulbonneville.com>",
        "type": "personal",
        "icon": null,
        "description": null,
        "projectRelations": [
          {
            "createdAt": "2025-06-27T08:10:34.980Z",
            "updatedAt": "2025-06-27T08:10:34.980Z",
            "role": "project:personalOwner",
            "userId": "7a45348e-c410-42f1-b4b3-a1dc290190b0",
            "projectId": "KRe5oDYWZLNq5WHX",
            "user": {
              "createdAt": "2025-06-27T08:10:31.689Z",
              "updatedAt": "2025-06-27T08:43:03.885Z",
              "id": "7a45348e-c410-42f1-b4b3-a1dc290190b0",
              "email": "paul@paulbonneville.com",
              "firstName": "Paul",
              "lastName": "Bonneville",
              "personalizationAnswers": {
                "version": "v4",
                "personalization_survey_submitted_at": "2025-06-27T08:11:43.577Z",
                "personalization_survey_n8n_version": "1.99.1",
                "companyType": "personal",
                "reportedSource": "youtube"
              },
              "settings": {
                "userActivated": true,
                "easyAIWorkflowOnboarded": true,
                "firstSuccessfulWorkflowId": "OXZoJZO8QesvwtWy",
                "userActivatedAt": 1751013777289
              },
              "role": "global:owner",
              "disabled": false,
              "mfaEnabled": false,
              "isPending": false
            }
          }
        ]
      }
    }
  ],
  "tags": []
}
